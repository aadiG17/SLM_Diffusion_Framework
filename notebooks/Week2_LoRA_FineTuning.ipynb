{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 — LoRA Fine-Tuning of SLM\n",
    "Align Small Language Model embeddings with Diffusion CLIP Encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c2c27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cse-sdpl/anaconda3/envs/gpu_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diffusers: 0.26.3\n",
      "huggingface_hub: 0.20.3\n",
      "Torch CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import diffusers, huggingface_hub, torch\n",
    "print(\"diffusers:\", diffusers.__version__)\n",
    "print(\"huggingface_hub:\", huggingface_hub.__version__)\n",
    "print(\"Torch CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install peft==0.10.0 transformers==4.37.2 accelerate==0.29.3 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cse-sdpl/anaconda3/envs/gpu_env/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/cse-sdpl/anaconda3/envs/gpu_env/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import torch, pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLM & Diffusion Model Loaded Successfully\n"
     ]
    }
   ],
   "source": [
    "slm_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(slm_name)\n",
    "slm = AutoModelForCausalLM.from_pretrained(slm_name, torch_dtype=torch.float16).to(\"cuda\")\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "clip_encoder = pipe.text_encoder\n",
    "print(\"SLM & Diffusion Model Loaded Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved\n"
     ]
    }
   ],
   "source": [
    "data = {\"caption\": [\n",
    "    \"a sunset over the ocean\",\n",
    "    \"a cat sitting on a laptop\",\n",
    "    \"a futuristic city skyline\",\n",
    "    \"a person walking in rain with umbrella\",\n",
    "] * 25}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"../data/mini_text_image_dataset.csv\", index=False)\n",
    "print(\"Dataset saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,126,400 || all params: 1,101,174,784 || trainable%: 0.10229075496156657\n"
     ]
    }
   ],
   "source": [
    "config = LoraConfig(task_type=TaskType.CAUSAL_LM, r=8, lora_alpha=16, target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05)\n",
    "slm_lora = get_peft_model(slm, config)\n",
    "slm_lora.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 17.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Fine-tuning Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def dummy_train(slm, tokenizer, df):\n",
    "    optimizer = torch.optim.AdamW(slm.parameters(), lr=1e-4)\n",
    "    slm.train()\n",
    "    for caption in tqdm(df['caption'][:50], desc=\"Training\"):\n",
    "        inputs = tokenizer(caption, return_tensors=\"pt\", truncation=True, max_length=128).to(\"cuda\")\n",
    "        outputs = slm(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(\"LoRA Fine-tuning Complete\")\n",
    "dummy_train(slm_lora, tokenizer, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA adapter saved to ../adapters/slm_lora_adapter/\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"../adapters/slm_lora_adapter/\"\n",
    "slm_lora.save_pretrained(output_dir)\n",
    "print(f\"LoRA adapter saved to {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
